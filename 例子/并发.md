## 并发

```go
package main

import (
	"fmt"

	"github.com/gocolly/colly"
)

func main() {
	// 初始化默认收集器
	c := colly.NewCollector(
        // 最大深度为2，即在所爬取的页面上的所有链接和这些链接页面上的链接会被访问
		colly.MaxDepth(2),
		colly.Async(true),
	)

    // 限制只有两个线程去访问页面
	c.Limit(&colly.LimitRule{DomainGlob: "*", Parallelism: 2})

    // 处理具有href的a标签
	c.OnHTML("a[href]", func(e *colly.HTMLElement) {
		link := e.Attr("href")
		// 打印链接
		fmt.Println(link)
		// 访问新连接
		e.Request.Visit(link)
	})

	// 开始爬虫
	c.Visit("https://en.wikipedia.org/")
	// 等待所有线程都结束
	c.Wait()
}
```

